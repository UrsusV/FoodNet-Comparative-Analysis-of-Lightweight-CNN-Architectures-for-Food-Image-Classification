{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc2be362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üì¶ PyTorch: 2.9.0+cu130\n",
      "üî• CUDA: 13.0\n",
      "üíé GPU: NVIDIA GeForce RTX 4070\n",
      "üìä Memory: 12.9 GB\n",
      "üéØ Device: cuda\n",
      "‚úÖ sm_120 Ready: True\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Imports & GPU Setup\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n",
    "os.environ[\"TORCH_CUDA_ARCH_LIST\"] = \"12.0;8.9;8.6\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import mobilenet_v3_small, efficientnet_b0, resnet18\n",
    "import torchvision.datasets as datasets\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"üì¶ PyTorch: {torch.__version__}\")\n",
    "print(f\"üî• CUDA: {torch.version.cuda}\")\n",
    "print(f\"üíé GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
    "print(f\"üìä Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "print(f\"üéØ Device: {device}\")\n",
    "print(f\"‚úÖ sm_120 Ready: {'12.0' in os.environ.get('TORCH_CUDA_ARCH_LIST', '')}\")\n",
    "print(\"=\"*70)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5d2bf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî™ Splitting FoodNet dataset...\n",
      "‚úÖ FoodNet dataset split complete!\n",
      "üìÅ 0 classes, 0 total images\n",
      "üìÇ New structure: D:\\FoodNet\\data\\train/, val/, test/\n"
     ]
    }
   ],
   "source": [
    "# Dataset Splitter\n",
    "\n",
    "def split_dataset_once(raw_path=r\"D:\\FoodNet\\Food Classification dataset\", split_path=r\"D:\\FoodNet\\data\"):\n",
    "    \"\"\"Split YOUR dataset into train/val/test (70/15/15)\"\"\"\n",
    "    print(\"üî™ Splitting FoodNet dataset...\")\n",
    "    os.makedirs(f\"{split_path}/train\", exist_ok=True)\n",
    "    os.makedirs(f\"{split_path}/val\", exist_ok=True)\n",
    "    os.makedirs(f\"{split_path}/test\", exist_ok=True)\n",
    "    \n",
    "    class_count = 0\n",
    "    total_images = 0\n",
    "    \n",
    "    for class_name in os.listdir(raw_path):\n",
    "        class_path = os.path.join(raw_path, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "            \n",
    "        images = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        if len(images) == 0:\n",
    "            continue\n",
    "            \n",
    "        class_count += 1\n",
    "        total_images += len(images)\n",
    "        \n",
    "        # 70% train, 15% val, 15% test\n",
    "        train_imgs, temp_imgs = train_test_split(images, test_size=0.3, random_state=42)\n",
    "        val_imgs, test_imgs = train_test_split(temp_imgs, test_size=0.5, random_state=42)\n",
    "        \n",
    "        # Create class directories\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            os.makedirs(f\"{split_path}/{split}/{class_name}\", exist_ok=True)\n",
    "        \n",
    "        # Move files\n",
    "        for split_imgs, split_name in [(train_imgs, 'train'), (val_imgs, 'val'), (test_imgs, 'test')]:\n",
    "            for img in split_imgs:\n",
    "                src = os.path.join(class_path, img)\n",
    "                dst = f\"{split_path}/{split_name}/{class_name}/{img}\"\n",
    "                shutil.move(src, dst)\n",
    "    \n",
    "    print(f\"‚úÖ FoodNet dataset split complete!\")\n",
    "    print(f\"üìÅ {class_count} classes, {total_images} total images\")\n",
    "    print(f\"üìÇ New structure: D:\\\\FoodNet\\\\data\\\\train/, val/, test/\")\n",
    "\n",
    "# RUN THIS FIRST (ONLY ONCE)\n",
    "split_dataset_once()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc9cd92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loaders & Transforms\n",
    "\n",
    "def get_data_loaders(data_path=r\"D:\\FoodNet\\data\", batch_size=16):\n",
    "    \"\"\"Standard ImageNet transforms + augmentation\"\"\"\n",
    "    train_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # no saturation for grayscale\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229]),\n",
    "])\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229]),\n",
    "])\n",
    "    \n",
    "    # Load splitted datasets\n",
    "    train_ds = datasets.ImageFolder(f\"{data_path}/train\", train_transform)\n",
    "    val_ds = datasets.ImageFolder(f\"{data_path}/val\", test_transform)\n",
    "    test_ds = datasets.ImageFolder(f\"{data_path}/test\", test_transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, \n",
    "                             num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, \n",
    "                           num_workers=4, pin_memory=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, \n",
    "                            num_workers=4, pin_memory=True)\n",
    "    \n",
    "    print(f\"üìä Dataset sizes: Train={len(train_ds)}, Val={len(val_ds)}, Test={len(test_ds)}\")\n",
    "    print(f\"üè∑Ô∏è  Classes: {len(train_ds.classes)}\")\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, train_ds.classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3c323ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import (\n",
    "    mobilenet_v3_small,\n",
    "    efficientnet_b0,\n",
    "    resnet18\n",
    ")\n",
    "\n",
    "def _convert_first_conv_to_grayscale(conv: nn.Conv2d):\n",
    "    \"\"\"\n",
    "    Convert a Conv2d layer from 3-channel RGB to 1-channel grayscale\n",
    "    by averaging pretrained weights.\n",
    "    \"\"\"\n",
    "    new_conv = nn.Conv2d(\n",
    "        in_channels=1,\n",
    "        out_channels=conv.out_channels,\n",
    "        kernel_size=conv.kernel_size,\n",
    "        stride=conv.stride,\n",
    "        padding=conv.padding,\n",
    "        dilation=conv.dilation,\n",
    "        groups=conv.groups,\n",
    "        bias=(conv.bias is not None),\n",
    "        padding_mode=conv.padding_mode,\n",
    "    )\n",
    "\n",
    "    # Average RGB weights ‚Üí grayscale\n",
    "    with torch.no_grad():\n",
    "        new_conv.weight.copy_(conv.weight.mean(dim=1, keepdim=True))\n",
    "        if conv.bias is not None:\n",
    "            new_conv.bias.copy_(conv.bias)\n",
    "\n",
    "    return new_conv\n",
    "\n",
    "\n",
    "def get_model(model_name, num_classes=35, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Model factory:\n",
    "      - Single-channel input: [B, 1, 128, 128]\n",
    "      - ImageNet-pretrained backbones\n",
    "      - MobileNetV3-Small, EfficientNet-B0, ResNet-18\n",
    "    \"\"\"\n",
    "    print(f\"üîÑ Loading {model_name} (ImageNet pretrained, grayscale)...\")\n",
    "\n",
    "    if model_name == \"mobilenet\":\n",
    "        model = mobilenet_v3_small(weights=\"IMAGENET1K_V1\")\n",
    "        model.features[0][0] = _convert_first_conv_to_grayscale(\n",
    "            model.features[0][0]\n",
    "        )\n",
    "        model.classifier[3] = nn.Linear(\n",
    "            model.classifier[3].in_features, num_classes\n",
    "        )\n",
    "\n",
    "    elif model_name == \"efficientnet\":\n",
    "        model = efficientnet_b0(weights=\"IMAGENET1K_V1\")\n",
    "        model.features[0][0] = _convert_first_conv_to_grayscale(\n",
    "            model.features[0][0]\n",
    "        )\n",
    "        model.classifier[1] = nn.Linear(\n",
    "            model.classifier[1].in_features, num_classes\n",
    "        )\n",
    "\n",
    "    elif model_name == \"resnet\":\n",
    "        model = resnet18(weights=\"IMAGENET1K_V1\")\n",
    "        model.conv1 = _convert_first_conv_to_grayscale(model.conv1)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Model must be 'mobilenet', 'efficientnet', or 'resnet'\")\n",
    "\n",
    "    # Print params\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"üìà Params: {total_params/1e6:.2f}M (trainable: {trainable_params/1e6:.2f}M)\")\n",
    "\n",
    "    return model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c68a6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop (edited)\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs=10, lr=0.001, model_name=\"model\"):\n",
    "    \"\"\"GPU OPTIMIZED with AMP + Stability Fixes + Proper Checkpoint Resume\"\"\"\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "    # ---- device (assumes you already set global device; keep this line if not) ----\n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.1, patience=3)\n",
    "\n",
    "    scaler = GradScaler(enabled=(device.type == \"cuda\"))\n",
    "\n",
    "    best_acc = 0.0\n",
    "    start_epoch = 0\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "\n",
    "    # ‚úÖ Use ONE consistent directory (recommended)\n",
    "    run_dir = Path(\"runs\") / model_name\n",
    "    run_dir.mkdir(parents=True, exist_ok=True)\n",
    "    checkpoint_path = run_dir / \"best_model.pt\"   # runs/<model_name>/best_model.pt\n",
    "    \n",
    " \n",
    "    # -------------------- LOAD CHECKPOINT --------------------\n",
    "    if checkpoint_path.exists():\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "        # Resume optimizer/scaler/history if present\n",
    "        if \"optimizer_state_dict\" in checkpoint:\n",
    "            optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        if \"scaler_state_dict\" in checkpoint:\n",
    "            scaler.load_state_dict(checkpoint[\"scaler_state_dict\"])\n",
    "\n",
    "        best_acc = float(checkpoint.get(\"best_val_acc\", 0.0))\n",
    "        history = checkpoint.get(\"history\", history)\n",
    "        start_epoch = int(checkpoint.get(\"epoch\", -1)) + 1\n",
    "\n",
    "        print(f\"‚úÖ Resumed: {checkpoint_path} | start_epoch={start_epoch} | best_acc={best_acc:.2f}%\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è No checkpoint found at {checkpoint_path}, starting fresh.\")\n",
    "\n",
    "    # -------------------- TRAIN --------------------\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss, train_correct = 0.0, 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            # AMP forward\n",
    "            with autocast(enabled=(device.type == \"cuda\"), dtype=torch.float16):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            # AMP backward\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += float(loss.item())\n",
    "            train_correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss, val_correct = 0.0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "                with autocast(enabled=(device.type == \"cuda\"), dtype=torch.float16):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += float(loss.item())\n",
    "                val_correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "        # Metrics\n",
    "        train_acc = 100.0 * train_correct / len(train_loader.dataset)\n",
    "        val_acc = 100.0 * val_correct / len(val_loader.dataset)\n",
    "        train_loss /= max(1, len(train_loader))\n",
    "        val_loss /= max(1, len(val_loader))\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1:2d}/{epochs}: Train={train_acc:6.2f}% | Val={val_acc:6.2f}% | \"\n",
    "              f\"Loss T/V={train_loss:.3f}/{val_loss:.3f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save({\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"scaler_state_dict\": scaler.state_dict(),\n",
    "                \"best_val_acc\": best_acc,\n",
    "                \"history\": history\n",
    "            }, checkpoint_path)\n",
    "            print(f\"üíæ Saved best -> {checkpoint_path} (Val={best_acc:.2f}%)\")\n",
    "\n",
    "        # Scheduler step (mode='max' so use val_acc)\n",
    "        scheduler.step(val_acc)\n",
    "\n",
    "    print(f\"üèÜ Best Val Accuracy: {best_acc:.2f}%\")\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f423486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation & Matrices\n",
    "\n",
    "def evaluate_model(model, test_loader, class_names, model_name=\"model\"):\n",
    "    \"\"\"Comprehensive evaluation: accuracy, F1, confusion matrix, inference time\"\"\"\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    all_probs = []\n",
    "    \n",
    "    # Inference time measurement\n",
    "    start_time = time.time()\n",
    "    num_images = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            \n",
    "            num_images += inputs.size(0)\n",
    "    \n",
    "    inference_time = (time.time() - start_time) / num_images * 1000  # ms per image\n",
    "    \n",
    "    # Metrics\n",
    "    accuracy = 100. * np.mean(np.array(all_preds) == np.array(all_labels))\n",
    "    \n",
    "    print(f\"\\nüìä {model_name.upper()} TEST RESULTS:\")\n",
    "    print(f\"   Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"   Inference: {inference_time:.2f}ms/image\")\n",
    "    \n",
    "    # Save classification report\n",
    "    report = classification_report(all_labels, all_preds, target_names=class_names, \n",
    "                                  output_dict=True)\n",
    "    pd.DataFrame(report).round(3).to_csv(f\"runs/{model_name}/classification_report.csv\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    sns.heatmap(cm, annot=False, cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'{model_name.upper()} Confusion Matrix')\n",
    "    plt.savefig(f\"runs/{model_name}/confusion_matrix.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return accuracy, inference_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0054abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Feature Visualization (t-SNE/PCA)\n",
    "\n",
    "def evaluate_model(model, test_loader, class_names, model_name=\"model\"):\n",
    "    \n",
    "    from torch.cuda.amp import autocast \n",
    "    \n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    all_probs = []\n",
    "    \n",
    "    # Inference time measurement\n",
    "    start_time = time.time()\n",
    "    num_images = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            \n",
    "            with autocast(dtype=torch.float16):\n",
    "                outputs = model(inputs)\n",
    "            \n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            \n",
    "            num_images += inputs.size(0)\n",
    "    \n",
    "    inference_time = (time.time() - start_time) / num_images * 1000  # ms per image\n",
    "    \n",
    "    # Metrics\n",
    "    accuracy = 100. * np.mean(np.array(all_preds) == np.array(all_labels))\n",
    "    \n",
    "    print(f\"\\nüìä {model_name.upper()} TEST RESULTS:\")\n",
    "    print(f\"   Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"   Inference: {inference_time:.2f}ms/image\")\n",
    "    \n",
    "    # Save classification report\n",
    "    report = classification_report(all_labels, all_preds, target_names=class_names, \n",
    "                                  output_dict=True)\n",
    "    pd.DataFrame(report).round(3).to_csv(f\"runs/{model_name}/classification_report.csv\")\n",
    "    \n",
    "    # Confusion Matrix (RTX memory safe)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    sns.heatmap(cm, annot=False, cmap='Blues', \n",
    "                xticklabels=class_names[:10] + ['...'] + class_names[-5:],  # Truncated for 35 classes\n",
    "                yticklabels=class_names[:10] + ['...'] + class_names[-5:])\n",
    "    plt.title(f'{model_name.upper()} Confusion Matrix (35 Food Classes)')\n",
    "    plt.savefig(f\"runs/{model_name}/confusion_matrix.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return accuracy, inference_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81721520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ FoodNet: Starting 10-epoch experiments...\n",
      "Initial device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Main Experiment Runner\n",
    "\n",
    "def run_experiment(model_name, data_path=r\"D:\\FoodNet\\data\", epochs=1):\n",
    "    \"\"\"Run complete experiment for one model with flexible device.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üöÄ STARTING {model_name.upper()} EXPERIMENT ({epochs} epochs)\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Data\n",
    "    train_loader, val_loader, test_loader, class_names = get_data_loaders(data_path)\n",
    "    \n",
    "    # Model\n",
    "    model = get_model(model_name, len(class_names))  # must use global `device`\n",
    "    \n",
    "    # Train\n",
    "    history = train_model(model, train_loader, val_loader, epochs, model_name=model_name)\n",
    "    \n",
    "    # Checkpoint\n",
    "    checkpoint_path = f\"runs/{model_name}/best_model.pt\"\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        best_val_acc = checkpoint.get(\"best_val_acc\", max(history[\"val_acc\"]))\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è No checkpoint found for {model_name}, using current model\")\n",
    "        best_val_acc = max(history[\"val_acc\"]) if history[\"val_acc\"] else 0\n",
    "    \n",
    "    # Evaluate\n",
    "    accuracy, inference_time = evaluate_model(model, test_loader, class_names, model_name)\n",
    "    \n",
    "    \n",
    "    # Results\n",
    "    results = {\n",
    "        \"model\": model_name,\n",
    "        \"best_val_acc\": best_val_acc,\n",
    "        \"test_acc\": accuracy,\n",
    "        \"inference_time_ms\": inference_time,\n",
    "        \"num_classes\": len(class_names),\n",
    "    }\n",
    "    pd.DataFrame([results]).to_csv(f\"runs/{model_name}/results_summary.csv\", index=False)\n",
    "    \n",
    "    print(f\"‚úÖ {model_name.upper()} COMPLETE! Test Acc: {accuracy:.2f}%\")\n",
    "    return results\n",
    "\n",
    "print(\"üéØ FoodNet: Starting 10-epoch experiments...\")\n",
    "print(f\"Initial device: {device}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96a2ee4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ñ∂ Running MOBILENET on cuda...\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING MOBILENET EXPERIMENT (20 epochs)\n",
      "======================================================================\n",
      "üìä Dataset sizes: Train=16700, Val=3580, Test=3593\n",
      "üè∑Ô∏è  Classes: 34\n",
      "üîÑ Loading mobilenet (ImageNet pretrained, grayscale)...\n",
      "üìà Params: 1.55M (trainable: 1.55M)\n",
      "‚úÖ Resumed: runs\\mobilenet\\best_model.pt | start_epoch=20 | best_acc=69.61%\n",
      "üèÜ Best Val Accuracy: 69.61%\n",
      "\n",
      "üìä MOBILENET TEST RESULTS:\n",
      "   Accuracy: 68.08%\n",
      "   Inference: 5.64ms/image\n",
      "‚úÖ MOBILENET COMPLETE! Test Acc: 68.08%\n",
      "\n",
      "‚ñ∂ Running EFFICIENTNET on cuda...\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING EFFICIENTNET EXPERIMENT (20 epochs)\n",
      "======================================================================\n",
      "üìä Dataset sizes: Train=16700, Val=3580, Test=3593\n",
      "üè∑Ô∏è  Classes: 34\n",
      "üîÑ Loading efficientnet (ImageNet pretrained, grayscale)...\n",
      "üìà Params: 4.05M (trainable: 4.05M)\n",
      "‚úÖ Resumed: runs\\efficientnet\\best_model.pt | start_epoch=20 | best_acc=80.50%\n",
      "üèÜ Best Val Accuracy: 80.50%\n",
      "\n",
      "üìä EFFICIENTNET TEST RESULTS:\n",
      "   Accuracy: 77.68%\n",
      "   Inference: 4.93ms/image\n",
      "‚úÖ EFFICIENTNET COMPLETE! Test Acc: 77.68%\n",
      "\n",
      "‚ñ∂ Running RESNET on cuda...\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING RESNET EXPERIMENT (20 epochs)\n",
      "======================================================================\n",
      "üìä Dataset sizes: Train=16700, Val=3580, Test=3593\n",
      "üè∑Ô∏è  Classes: 34\n",
      "üîÑ Loading resnet (ImageNet pretrained, grayscale)...\n",
      "üìà Params: 11.19M (trainable: 11.19M)\n",
      "‚úÖ Resumed: runs\\resnet\\best_model.pt | start_epoch=18 | best_acc=67.60%\n",
      "Epoch 19/20: Train= 87.54% | Val= 67.49% | Loss T/V=0.410/1.237\n",
      "Epoch 20/20: Train= 88.66% | Val= 67.40% | Loss T/V=0.368/1.279\n",
      "üèÜ Best Val Accuracy: 67.60%\n",
      "\n",
      "üìä RESNET TEST RESULTS:\n",
      "   Accuracy: 66.46%\n",
      "   Inference: 5.37ms/image\n",
      "‚úÖ RESNET COMPLETE! Test Acc: 66.46%\n",
      "\n",
      "======================================================================\n",
      "üèÅ FOODNET 10-EPOCH EXPERIMENTS COMPLETE (with GPU‚ÜíCPU fallback)!\n",
      "          model  best_val_acc  test_acc  inference_time_ms  num_classes\n",
      "0     mobilenet         69.61     68.08               5.64           34\n",
      "1  efficientnet         80.50     77.68               4.93           34\n",
      "2        resnet         67.60     66.46               5.37           34\n",
      "\n",
      "üìÅ Results saved: D:\\FoodNet\\runs\\model_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for model_name in [\"mobilenet\", \"efficientnet\", \"resnet\"]:\n",
    "    print(f\"\\n‚ñ∂ Running {model_name.upper()} on {device}...\")\n",
    "    \n",
    "    try:\n",
    "        # Try on current device (likely cuda)\n",
    "        result = run_experiment(model_name, epochs=20)\n",
    "        results.append(result)\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        msg = str(e)\n",
    "        print(f\"‚ùå {model_name.upper()} FAILED on {device}: {msg}\")\n",
    "        \n",
    "        # Check for CUDA kernel image errors or generic CUDA failures\n",
    "        if \"no kernel image is available\" in msg or \"CUDA error\" in msg:\n",
    "            print(\"‚ö†Ô∏è CUDA issue detected. Switching to safe CPU mode for this model...\")\n",
    "            \n",
    "            # Switch global device to CPU\n",
    "            device = torch.device(\"cpu\")\n",
    "            torch.cuda.empty_cache()\n",
    "            print(f\"üîÑ New device: {device}\")\n",
    "            \n",
    "            # IMPORTANT: rerun with fresh model on CPU\n",
    "            try:\n",
    "                result = run_experiment(model_name, epochs=10)\n",
    "                results.append(result)\n",
    "            except Exception as e2:\n",
    "                print(f\"‚ùå {model_name.upper()} also failed on CPU: {e2}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Non-CUDA error, not retrying on CPU for this model.\")\n",
    "\n",
    "# Final comparison\n",
    "if results:\n",
    "    comparison_df = pd.DataFrame(results)\n",
    "    comparison_df.to_csv(r\"D:\\runs\\model_comparison.csv\", index=False)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üèÅ FOODNET 10-EPOCH EXPERIMENTS COMPLETE (with GPU‚ÜíCPU fallback)!\")\n",
    "    print(comparison_df.round(2))\n",
    "    print(\"\\nüìÅ Results saved: D:\\\\FoodNet\\\\runs\\\\model_comparison.csv\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No successful runs to summarize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d116d73",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
