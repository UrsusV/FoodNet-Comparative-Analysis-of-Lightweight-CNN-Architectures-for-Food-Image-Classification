{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2be362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üì¶ PyTorch: 2.9.0+cu130\n",
      "üî• CUDA: 13.0\n",
      "üíé GPU: NVIDIA GeForce RTX 4070\n",
      "üìä Memory: 12.9 GB\n",
      "üéØ Device: cuda\n",
      "‚úÖ sm_120 Ready: True\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Imports & GPU Setup\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n",
    "os.environ[\"TORCH_CUDA_ARCH_LIST\"] = \"12.0;8.9;8.6\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import mobilenet_v3_small, efficientnet_b0, resnet18\n",
    "import torchvision.datasets as datasets\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"üì¶ PyTorch: {torch.__version__}\")\n",
    "print(f\"üî• CUDA: {torch.version.cuda}\")\n",
    "print(f\"üíé GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
    "print(f\"üìä Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "print(f\"üéØ Device: {device}\")\n",
    "print(f\"‚úÖ sm_120 Ready: {'12.0' in os.environ.get('TORCH_CUDA_ARCH_LIST', '')}\")\n",
    "print(\"=\"*70)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5d2bf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî™ Splitting FoodNet dataset...\n",
      "‚úÖ FoodNet dataset split complete!\n",
      "üìÅ 0 classes, 0 total images\n",
      "üìÇ New structure: D:\\FoodNet\\data\\train/, val/, test/\n"
     ]
    }
   ],
   "source": [
    "# Dataset Splitter\n",
    "\n",
    "def split_dataset_once(raw_path=r\"D:\\FoodNet\\Food Classification dataset\", split_path=r\"D:\\FoodNet\\data\"):\n",
    "    \"\"\"Split YOUR dataset into train/val/test (70/15/15)\"\"\"\n",
    "    print(\"üî™ Splitting FoodNet dataset...\")\n",
    "    os.makedirs(f\"{split_path}/train\", exist_ok=True)\n",
    "    os.makedirs(f\"{split_path}/val\", exist_ok=True)\n",
    "    os.makedirs(f\"{split_path}/test\", exist_ok=True)\n",
    "    \n",
    "    class_count = 0\n",
    "    total_images = 0\n",
    "    \n",
    "    for class_name in os.listdir(raw_path):\n",
    "        class_path = os.path.join(raw_path, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "            \n",
    "        images = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        if len(images) == 0:\n",
    "            continue\n",
    "            \n",
    "        class_count += 1\n",
    "        total_images += len(images)\n",
    "        \n",
    "        # 70% train, 15% val, 15% test\n",
    "        train_imgs, temp_imgs = train_test_split(images, test_size=0.3, random_state=42)\n",
    "        val_imgs, test_imgs = train_test_split(temp_imgs, test_size=0.5, random_state=42)\n",
    "        \n",
    "        # Create class directories\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            os.makedirs(f\"{split_path}/{split}/{class_name}\", exist_ok=True)\n",
    "        \n",
    "        # Move files\n",
    "        for split_imgs, split_name in [(train_imgs, 'train'), (val_imgs, 'val'), (test_imgs, 'test')]:\n",
    "            for img in split_imgs:\n",
    "                src = os.path.join(class_path, img)\n",
    "                dst = f\"{split_path}/{split_name}/{class_name}/{img}\"\n",
    "                shutil.move(src, dst)\n",
    "    \n",
    "    print(f\"‚úÖ FoodNet dataset split complete!\")\n",
    "    print(f\"üìÅ {class_count} classes, {total_images} total images\")\n",
    "    print(f\"üìÇ New structure: D:\\\\FoodNet\\\\data\\\\train/, val/, test/\")\n",
    "\n",
    "# RUN THIS FIRST (ONLY ONCE)\n",
    "split_dataset_once()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc9cd92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loaders & Transforms\n",
    "\n",
    "def get_data_loaders(data_path=r\"D:\\FoodNet\\data\", batch_size=16):\n",
    "    \"\"\"Standard ImageNet transforms + augmentation\"\"\"\n",
    "    train_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # no saturation for grayscale\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229]),\n",
    "])\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229]),\n",
    "])\n",
    "    \n",
    "    # Load splitted datasets\n",
    "    train_ds = datasets.ImageFolder(f\"{data_path}/train\", train_transform)\n",
    "    val_ds = datasets.ImageFolder(f\"{data_path}/val\", test_transform)\n",
    "    test_ds = datasets.ImageFolder(f\"{data_path}/test\", test_transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, \n",
    "                             num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, \n",
    "                           num_workers=4, pin_memory=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, \n",
    "                            num_workers=4, pin_memory=True)\n",
    "    \n",
    "    print(f\"üìä Dataset sizes: Train={len(train_ds)}, Val={len(val_ds)}, Test={len(test_ds)}\")\n",
    "    print(f\"üè∑Ô∏è  Classes: {len(train_ds.classes)}\")\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, train_ds.classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3c323ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import (\n",
    "    mobilenet_v3_small,\n",
    "    efficientnet_b0,\n",
    "    resnet18\n",
    ")\n",
    "\n",
    "def _convert_first_conv_to_grayscale(conv: nn.Conv2d):\n",
    "    \"\"\"\n",
    "    Convert a Conv2d layer from 3-channel RGB to 1-channel grayscale\n",
    "    by averaging pretrained weights.\n",
    "    \"\"\"\n",
    "    new_conv = nn.Conv2d(\n",
    "        in_channels=1,\n",
    "        out_channels=conv.out_channels,\n",
    "        kernel_size=conv.kernel_size,\n",
    "        stride=conv.stride,\n",
    "        padding=conv.padding,\n",
    "        dilation=conv.dilation,\n",
    "        groups=conv.groups,\n",
    "        bias=(conv.bias is not None),\n",
    "        padding_mode=conv.padding_mode,\n",
    "    )\n",
    "\n",
    "    # Average RGB weights ‚Üí grayscale\n",
    "    with torch.no_grad():\n",
    "        new_conv.weight.copy_(conv.weight.mean(dim=1, keepdim=True))\n",
    "        if conv.bias is not None:\n",
    "            new_conv.bias.copy_(conv.bias)\n",
    "\n",
    "    return new_conv\n",
    "\n",
    "\n",
    "def get_model(model_name, num_classes=35, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Model factory:\n",
    "      - Single-channel input: [B, 1, 128, 128]\n",
    "      - ImageNet-pretrained backbones\n",
    "      - MobileNetV3-Small, EfficientNet-B0, ResNet-18\n",
    "    \"\"\"\n",
    "    print(f\"üîÑ Loading {model_name} (ImageNet pretrained, grayscale)...\")\n",
    "\n",
    "    if model_name == \"mobilenet\":\n",
    "        model = mobilenet_v3_small(weights=\"IMAGENET1K_V1\")\n",
    "        model.features[0][0] = _convert_first_conv_to_grayscale(\n",
    "            model.features[0][0]\n",
    "        )\n",
    "        model.classifier[3] = nn.Linear(\n",
    "            model.classifier[3].in_features, num_classes\n",
    "        )\n",
    "\n",
    "    elif model_name == \"efficientnet\":\n",
    "        model = efficientnet_b0(weights=\"IMAGENET1K_V1\")\n",
    "        model.features[0][0] = _convert_first_conv_to_grayscale(\n",
    "            model.features[0][0]\n",
    "        )\n",
    "        model.classifier[1] = nn.Linear(\n",
    "            model.classifier[1].in_features, num_classes\n",
    "        )\n",
    "\n",
    "    elif model_name == \"resnet\":\n",
    "        model = resnet18(weights=\"IMAGENET1K_V1\")\n",
    "        model.conv1 = _convert_first_conv_to_grayscale(model.conv1)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Model must be 'mobilenet', 'efficientnet', or 'resnet'\")\n",
    "\n",
    "    # Print params\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"üìà Params: {total_params/1e6:.2f}M (trainable: {trainable_params/1e6:.2f}M)\")\n",
    "\n",
    "    return model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c68a6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop (edited)\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs=10, lr=0.001, model_name=\"model\"):\n",
    "    \"\"\"GPU OPTIMIZED with AMP + Stability Fixes + Proper Checkpoint Resume\"\"\"\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "    # ---- device (assumes you already set global device; keep this line if not) ----\n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.1, patience=3)\n",
    "\n",
    "    scaler = GradScaler(enabled=(device.type == \"cuda\"))\n",
    "\n",
    "    best_acc = 0.0\n",
    "    start_epoch = 0\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "\n",
    "    # ‚úÖ Use ONE consistent directory (recommended)\n",
    "    run_dir = Path(\"runs\") / model_name\n",
    "    run_dir.mkdir(parents=True, exist_ok=True)\n",
    "    checkpoint_path = run_dir / \"best_model.pt\"   # runs/<model_name>/best_model.pt\n",
    "    \n",
    " \n",
    "    # -------------------- LOAD CHECKPOINT --------------------\n",
    "    if checkpoint_path.exists():\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "        # Resume optimizer/scaler/history if present\n",
    "        if \"optimizer_state_dict\" in checkpoint:\n",
    "            optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        if \"scaler_state_dict\" in checkpoint:\n",
    "            scaler.load_state_dict(checkpoint[\"scaler_state_dict\"])\n",
    "\n",
    "        best_acc = float(checkpoint.get(\"best_val_acc\", 0.0))\n",
    "        history = checkpoint.get(\"history\", history)\n",
    "        start_epoch = int(checkpoint.get(\"epoch\", -1)) + 1\n",
    "\n",
    "        print(f\"‚úÖ Resumed: {checkpoint_path} | start_epoch={start_epoch} | best_acc={best_acc:.2f}%\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è No checkpoint found at {checkpoint_path}, starting fresh.\")\n",
    "\n",
    "    # -------------------- TRAIN --------------------\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss, train_correct = 0.0, 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            # AMP forward\n",
    "            with autocast(enabled=(device.type == \"cuda\"), dtype=torch.float16):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            # AMP backward\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += float(loss.item())\n",
    "            train_correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss, val_correct = 0.0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "                with autocast(enabled=(device.type == \"cuda\"), dtype=torch.float16):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += float(loss.item())\n",
    "                val_correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "        # Metrics\n",
    "        train_acc = 100.0 * train_correct / len(train_loader.dataset)\n",
    "        val_acc = 100.0 * val_correct / len(val_loader.dataset)\n",
    "        train_loss /= max(1, len(train_loader))\n",
    "        val_loss /= max(1, len(val_loader))\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1:2d}/{epochs}: Train={train_acc:6.2f}% | Val={val_acc:6.2f}% | \"\n",
    "              f\"Loss T/V={train_loss:.3f}/{val_loss:.3f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save({\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"scaler_state_dict\": scaler.state_dict(),\n",
    "                \"best_val_acc\": best_acc,\n",
    "                \"history\": history\n",
    "            }, checkpoint_path)\n",
    "            print(f\"üíæ Saved best -> {checkpoint_path} (Val={best_acc:.2f}%)\")\n",
    "\n",
    "        # Scheduler step (mode='max' so use val_acc)\n",
    "        scheduler.step(val_acc)\n",
    "\n",
    "    print(f\"üèÜ Best Val Accuracy: {best_acc:.2f}%\")\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f423486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation & Matrices\n",
    "\n",
    "def evaluate_model(model, test_loader, class_names, model_name=\"model\"):\n",
    "    \"\"\"Comprehensive evaluation: accuracy, F1, confusion matrix, inference time\"\"\"\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    all_probs = []\n",
    "    \n",
    "    # Inference time measurement\n",
    "    start_time = time.time()\n",
    "    num_images = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            \n",
    "            num_images += inputs.size(0)\n",
    "    \n",
    "    inference_time = (time.time() - start_time) / num_images * 1000  # ms per image\n",
    "    \n",
    "    # Metrics\n",
    "    accuracy = 100. * np.mean(np.array(all_preds) == np.array(all_labels))\n",
    "    \n",
    "    print(f\"\\nüìä {model_name.upper()} TEST RESULTS:\")\n",
    "    print(f\"   Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"   Inference: {inference_time:.2f}ms/image\")\n",
    "    \n",
    "    # Save classification report\n",
    "    report = classification_report(all_labels, all_preds, target_names=class_names, \n",
    "                                  output_dict=True)\n",
    "    pd.DataFrame(report).round(3).to_csv(f\"runs/{model_name}/classification_report.csv\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    sns.heatmap(cm, annot=False, cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'{model_name.upper()} Confusion Matrix')\n",
    "    plt.savefig(f\"runs/{model_name}/confusion_matrix.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return accuracy, inference_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0054abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Feature Visualization (t-SNE/PCA)\n",
    "\n",
    "def evaluate_model(model, test_loader, class_names, model_name=\"model\"):\n",
    "    \n",
    "    from torch.cuda.amp import autocast \n",
    "    \n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    all_probs = []\n",
    "    \n",
    "    # Inference time measurement\n",
    "    start_time = time.time()\n",
    "    num_images = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            \n",
    "            with autocast(dtype=torch.float16):\n",
    "                outputs = model(inputs)\n",
    "            \n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            \n",
    "            num_images += inputs.size(0)\n",
    "    \n",
    "    inference_time = (time.time() - start_time) / num_images * 1000  # ms per image\n",
    "    \n",
    "    # Metrics\n",
    "    accuracy = 100. * np.mean(np.array(all_preds) == np.array(all_labels))\n",
    "    \n",
    "    print(f\"\\nüìä {model_name.upper()} TEST RESULTS:\")\n",
    "    print(f\"   Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"   Inference: {inference_time:.2f}ms/image\")\n",
    "    \n",
    "    # Save classification report\n",
    "    report = classification_report(all_labels, all_preds, target_names=class_names, \n",
    "                                  output_dict=True)\n",
    "    pd.DataFrame(report).round(3).to_csv(f\"runs/{model_name}/classification_report.csv\")\n",
    "    \n",
    "    # Confusion Matrix (RTX memory safe)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    sns.heatmap(cm, annot=False, cmap='Blues', \n",
    "                xticklabels=class_names[:10] + ['...'] + class_names[-5:],  # Truncated for 35 classes\n",
    "                yticklabels=class_names[:10] + ['...'] + class_names[-5:])\n",
    "    plt.title(f'{model_name.upper()} Confusion Matrix (35 Food Classes)')\n",
    "    plt.savefig(f\"runs/{model_name}/confusion_matrix.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return accuracy, inference_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81721520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ FoodNet: Starting 10-epoch experiments...\n",
      "Initial device: cuda\n",
      "\n",
      "‚ñ∂ Running MOBILENET on cuda...\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING MOBILENET EXPERIMENT (20 epochs)\n",
      "======================================================================\n",
      "üìä Dataset sizes: Train=16700, Val=3580, Test=3593\n",
      "üè∑Ô∏è  Classes: 34\n",
      "üîÑ Loading mobilenet (ImageNet pretrained, grayscale)...\n",
      "üìà Params: 1.55M (trainable: 1.55M)\n",
      "‚ö†Ô∏è No checkpoint found at runs\\mobilenet\\best_model.pt, starting fresh.\n",
      "Epoch  1/20: Train= 38.12% | Val= 47.51% | Loss T/V=2.145/1.874\n",
      "üíæ Saved best -> runs\\mobilenet\\best_model.pt (Val=47.51%)\n",
      "Epoch  2/20: Train= 51.14% | Val= 51.56% | Loss T/V=1.669/1.739\n",
      "üíæ Saved best -> runs\\mobilenet\\best_model.pt (Val=51.56%)\n",
      "Epoch  3/20: Train= 55.40% | Val= 56.82% | Loss T/V=1.505/1.533\n",
      "üíæ Saved best -> runs\\mobilenet\\best_model.pt (Val=56.82%)\n",
      "Epoch  4/20: Train= 59.01% | Val= 56.45% | Loss T/V=1.386/1.524\n",
      "Epoch  5/20: Train= 60.63% | Val= 60.53% | Loss T/V=1.307/1.374\n",
      "üíæ Saved best -> runs\\mobilenet\\best_model.pt (Val=60.53%)\n",
      "Epoch  6/20: Train= 63.34% | Val= 60.36% | Loss T/V=1.221/1.401\n",
      "Epoch  7/20: Train= 64.85% | Val= 61.06% | Loss T/V=1.164/1.369\n",
      "üíæ Saved best -> runs\\mobilenet\\best_model.pt (Val=61.06%)\n",
      "Epoch  8/20: Train= 66.08% | Val= 61.48% | Loss T/V=1.118/1.312\n",
      "üíæ Saved best -> runs\\mobilenet\\best_model.pt (Val=61.48%)\n",
      "Epoch  9/20: Train= 67.67% | Val= 59.86% | Loss T/V=1.057/1.461\n",
      "Epoch 10/20: Train= 69.04% | Val= 61.73% | Loss T/V=1.008/1.443\n",
      "üíæ Saved best -> runs\\mobilenet\\best_model.pt (Val=61.73%)\n",
      "Epoch 11/20: Train= 70.73% | Val= 60.50% | Loss T/V=0.952/1.484\n",
      "Epoch 12/20: Train= 71.50% | Val= 62.85% | Loss T/V=0.919/1.387\n",
      "üíæ Saved best -> runs\\mobilenet\\best_model.pt (Val=62.85%)\n",
      "Epoch 13/20: Train= 72.71% | Val= 57.60% | Loss T/V=0.885/1.729\n",
      "Epoch 14/20: Train= 73.84% | Val= 59.80% | Loss T/V=0.840/1.667\n",
      "Epoch 15/20: Train= 74.51% | Val= 60.50% | Loss T/V=0.810/1.524\n",
      "Epoch 16/20: Train= 75.03% | Val= 61.28% | Loss T/V=0.788/1.496\n",
      "Epoch 17/20: Train= 84.31% | Val= 68.52% | Loss T/V=0.491/1.196\n",
      "üíæ Saved best -> runs\\mobilenet\\best_model.pt (Val=68.52%)\n",
      "Epoch 18/20: Train= 87.31% | Val= 68.58% | Loss T/V=0.397/1.207\n",
      "üíæ Saved best -> runs\\mobilenet\\best_model.pt (Val=68.58%)\n",
      "Epoch 19/20: Train= 89.19% | Val= 69.02% | Loss T/V=0.341/1.213\n",
      "üíæ Saved best -> runs\\mobilenet\\best_model.pt (Val=69.02%)\n",
      "Epoch 20/20: Train= 89.74% | Val= 69.61% | Loss T/V=0.321/1.219\n",
      "üíæ Saved best -> runs\\mobilenet\\best_model.pt (Val=69.61%)\n",
      "üèÜ Best Val Accuracy: 69.61%\n",
      "\n",
      "üìä MOBILENET TEST RESULTS:\n",
      "   Accuracy: 68.08%\n",
      "   Inference: 6.56ms/image\n",
      "‚úÖ MOBILENET COMPLETE! Test Acc: 68.08%\n",
      "\n",
      "‚ñ∂ Running EFFICIENTNET on cuda...\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING EFFICIENTNET EXPERIMENT (20 epochs)\n",
      "======================================================================\n",
      "üìä Dataset sizes: Train=16700, Val=3580, Test=3593\n",
      "üè∑Ô∏è  Classes: 34\n",
      "üîÑ Loading efficientnet (ImageNet pretrained, grayscale)...\n",
      "üìà Params: 4.05M (trainable: 4.05M)\n",
      "‚ö†Ô∏è No checkpoint found at runs\\efficientnet\\best_model.pt, starting fresh.\n",
      "Epoch  1/20: Train= 44.17% | Val= 59.94% | Loss T/V=1.956/1.351\n",
      "üíæ Saved best -> runs\\efficientnet\\best_model.pt (Val=59.94%)\n",
      "Epoch  2/20: Train= 58.55% | Val= 64.94% | Loss T/V=1.416/1.171\n",
      "üíæ Saved best -> runs\\efficientnet\\best_model.pt (Val=64.94%)\n",
      "Epoch  3/20: Train= 62.98% | Val= 66.45% | Loss T/V=1.239/1.129\n",
      "üíæ Saved best -> runs\\efficientnet\\best_model.pt (Val=66.45%)\n",
      "Epoch  4/20: Train= 65.83% | Val= 69.86% | Loss T/V=1.152/0.985\n",
      "üíæ Saved best -> runs\\efficientnet\\best_model.pt (Val=69.86%)\n",
      "Epoch  5/20: Train= 68.60% | Val= 71.23% | Loss T/V=1.045/0.978\n",
      "üíæ Saved best -> runs\\efficientnet\\best_model.pt (Val=71.23%)\n",
      "Epoch  6/20: Train= 70.40% | Val= 69.83% | Loss T/V=0.991/1.028\n",
      "Epoch  7/20: Train= 71.45% | Val= 72.51% | Loss T/V=0.949/0.974\n",
      "üíæ Saved best -> runs\\efficientnet\\best_model.pt (Val=72.51%)\n",
      "Epoch  8/20: Train= 72.41% | Val= 71.03% | Loss T/V=0.909/1.021\n",
      "Epoch  9/20: Train= 73.32% | Val= 70.42% | Loss T/V=0.862/1.032\n",
      "Epoch 10/20: Train= 74.73% | Val= 74.16% | Loss T/V=0.824/0.909\n",
      "üíæ Saved best -> runs\\efficientnet\\best_model.pt (Val=74.16%)\n",
      "Epoch 11/20: Train= 75.84% | Val= 73.49% | Loss T/V=0.799/0.968\n",
      "Epoch 12/20: Train= 76.28% | Val= 71.65% | Loss T/V=0.774/0.998\n",
      "Epoch 13/20: Train= 77.22% | Val= 72.40% | Loss T/V=0.738/1.039\n",
      "Epoch 14/20: Train= 77.37% | Val= 72.91% | Loss T/V=0.721/0.937\n",
      "Epoch 15/20: Train= 86.26% | Val= 79.02% | Loss T/V=0.437/0.770\n",
      "üíæ Saved best -> runs\\efficientnet\\best_model.pt (Val=79.02%)\n",
      "Epoch 16/20: Train= 89.34% | Val= 79.78% | Loss T/V=0.340/0.772\n",
      "üíæ Saved best -> runs\\efficientnet\\best_model.pt (Val=79.78%)\n",
      "Epoch 17/20: Train= 90.59% | Val= 79.75% | Loss T/V=0.294/0.782\n",
      "Epoch 18/20: Train= 91.07% | Val= 79.72% | Loss T/V=0.276/0.792\n",
      "Epoch 19/20: Train= 92.34% | Val= 80.17% | Loss T/V=0.246/0.802\n",
      "üíæ Saved best -> runs\\efficientnet\\best_model.pt (Val=80.17%)\n",
      "Epoch 20/20: Train= 92.83% | Val= 80.50% | Loss T/V=0.227/0.831\n",
      "üíæ Saved best -> runs\\efficientnet\\best_model.pt (Val=80.50%)\n",
      "üèÜ Best Val Accuracy: 80.50%\n",
      "\n",
      "üìä EFFICIENTNET TEST RESULTS:\n",
      "   Accuracy: 77.68%\n",
      "   Inference: 11.04ms/image\n",
      "‚úÖ EFFICIENTNET COMPLETE! Test Acc: 77.68%\n",
      "\n",
      "‚ñ∂ Running RESNET on cuda...\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING RESNET EXPERIMENT (20 epochs)\n",
      "======================================================================\n",
      "üìä Dataset sizes: Train=16700, Val=3580, Test=3593\n",
      "üè∑Ô∏è  Classes: 34\n",
      "üîÑ Loading resnet (ImageNet pretrained, grayscale)...\n",
      "üìà Params: 11.19M (trainable: 11.19M)\n",
      "‚ö†Ô∏è No checkpoint found at runs\\resnet\\best_model.pt, starting fresh.\n",
      "Epoch  1/20: Train= 26.78% | Val= 33.27% | Loss T/V=2.609/2.483\n",
      "üíæ Saved best -> runs\\resnet\\best_model.pt (Val=33.27%)\n",
      "Epoch  2/20: Train= 39.93% | Val= 44.75% | Loss T/V=2.090/1.953\n",
      "üíæ Saved best -> runs\\resnet\\best_model.pt (Val=44.75%)\n",
      "Epoch  3/20: Train= 45.60% | Val= 47.29% | Loss T/V=1.869/1.813\n",
      "üíæ Saved best -> runs\\resnet\\best_model.pt (Val=47.29%)\n",
      "Epoch  4/20: Train= 49.28% | Val= 53.10% | Loss T/V=1.739/1.637\n",
      "üíæ Saved best -> runs\\resnet\\best_model.pt (Val=53.10%)\n",
      "Epoch  5/20: Train= 52.71% | Val= 52.40% | Loss T/V=1.617/1.725\n",
      "Epoch  6/20: Train= 55.00% | Val= 57.63% | Loss T/V=1.524/1.484\n",
      "üíæ Saved best -> runs\\resnet\\best_model.pt (Val=57.63%)\n",
      "Epoch  7/20: Train= 57.38% | Val= 57.09% | Loss T/V=1.441/1.447\n",
      "Epoch  8/20: Train= 59.89% | Val= 57.40% | Loss T/V=1.349/1.479\n",
      "Epoch  9/20: Train= 61.70% | Val= 59.41% | Loss T/V=1.285/1.418\n",
      "üíæ Saved best -> runs\\resnet\\best_model.pt (Val=59.41%)\n",
      "Epoch 10/20: Train= 63.19% | Val= 56.09% | Loss T/V=1.217/1.585\n",
      "Epoch 11/20: Train= 64.67% | Val= 58.91% | Loss T/V=1.170/1.436\n",
      "Epoch 12/20: Train= 66.49% | Val= 58.77% | Loss T/V=1.108/1.489\n",
      "Epoch 13/20: Train= 68.28% | Val= 57.37% | Loss T/V=1.053/1.527\n",
      "Epoch 14/20: Train= 77.93% | Val= 66.51% | Loss T/V=0.734/1.182\n",
      "üíæ Saved best -> runs\\resnet\\best_model.pt (Val=66.51%)\n",
      "Epoch 15/20: Train= 80.99% | Val= 67.07% | Loss T/V=0.620/1.167\n",
      "üíæ Saved best -> runs\\resnet\\best_model.pt (Val=67.07%)\n",
      "Epoch 16/20: Train= 83.23% | Val= 67.35% | Loss T/V=0.554/1.207\n",
      "üíæ Saved best -> runs\\resnet\\best_model.pt (Val=67.35%)\n",
      "Epoch 17/20: Train= 84.17% | Val= 67.35% | Loss T/V=0.505/1.218\n",
      "Epoch 18/20: Train= 86.11% | Val= 67.60% | Loss T/V=0.454/1.226\n",
      "üíæ Saved best -> runs\\resnet\\best_model.pt (Val=67.60%)\n",
      "Epoch 19/20: Train= 87.30% | Val= 66.98% | Loss T/V=0.415/1.262\n",
      "Epoch 20/20: Train= 88.30% | Val= 66.90% | Loss T/V=0.381/1.291\n",
      "üèÜ Best Val Accuracy: 67.60%\n",
      "\n",
      "üìä RESNET TEST RESULTS:\n",
      "   Accuracy: 66.46%\n",
      "   Inference: 8.95ms/image\n",
      "‚úÖ RESNET COMPLETE! Test Acc: 66.46%\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'D:\\FoodNet\\runs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 83\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results:\n\u001b[0;32m     82\u001b[0m     comparison_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n\u001b[1;32m---> 83\u001b[0m     \u001b[43mcomparison_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mFoodNet\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mruns\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmodel_comparison.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m)\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müèÅ FOODNET 10-EPOCH EXPERIMENTS COMPLETE (with GPU‚ÜíCPU fallback)!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'D:\\FoodNet\\runs'"
     ]
    }
   ],
   "source": [
    "# Main Experiment Runner\n",
    "\n",
    "def run_experiment(model_name, data_path=r\"D:\\FoodNet\\data\", epochs=10):\n",
    "    \"\"\"Run complete experiment for one model with flexible device.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üöÄ STARTING {model_name.upper()} EXPERIMENT ({epochs} epochs)\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Data\n",
    "    train_loader, val_loader, test_loader, class_names = get_data_loaders(data_path)\n",
    "    \n",
    "    # Model\n",
    "    model = get_model(model_name, len(class_names))  # must use global `device`\n",
    "    \n",
    "    # Train\n",
    "    history = train_model(model, train_loader, val_loader, epochs, model_name=model_name)\n",
    "    \n",
    "    # Checkpoint\n",
    "    checkpoint_path = f\"runs/{model_name}/best_model.pt\"\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        best_val_acc = checkpoint.get(\"best_val_acc\", max(history[\"val_acc\"]))\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è No checkpoint found for {model_name}, using current model\")\n",
    "        best_val_acc = max(history[\"val_acc\"]) if history[\"val_acc\"] else 0\n",
    "    \n",
    "    # Evaluate\n",
    "    accuracy, inference_time = evaluate_model(model, test_loader, class_names, model_name)\n",
    "    \n",
    "    \n",
    "    # Results\n",
    "    results = {\n",
    "        \"model\": model_name,\n",
    "        \"best_val_acc\": best_val_acc,\n",
    "        \"test_acc\": accuracy,\n",
    "        \"inference_time_ms\": inference_time,\n",
    "        \"num_classes\": len(class_names),\n",
    "    }\n",
    "    pd.DataFrame([results]).to_csv(f\"runs/{model_name}/results_summary.csv\", index=False)\n",
    "    \n",
    "    print(f\"‚úÖ {model_name.upper()} COMPLETE! Test Acc: {accuracy:.2f}%\")\n",
    "    return results\n",
    "\n",
    "print(\"üéØ FoodNet: Starting 10-epoch experiments...\")\n",
    "print(f\"Initial device: {device}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a2ee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for model_name in [\"mobilenet\", \"efficientnet\", \"resnet\"]:\n",
    "    print(f\"\\n‚ñ∂ Running {model_name.upper()} on {device}...\")\n",
    "    \n",
    "    try:\n",
    "        # Try on current device (likely cuda)\n",
    "        result = run_experiment(model_name, epochs=20)\n",
    "        results.append(result)\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        msg = str(e)\n",
    "        print(f\"‚ùå {model_name.upper()} FAILED on {device}: {msg}\")\n",
    "        \n",
    "        # Check for CUDA kernel image errors or generic CUDA failures\n",
    "        if \"no kernel image is available\" in msg or \"CUDA error\" in msg:\n",
    "            print(\"‚ö†Ô∏è CUDA issue detected. Switching to safe CPU mode for this model...\")\n",
    "            \n",
    "            # Switch global device to CPU\n",
    "            device = torch.device(\"cpu\")\n",
    "            torch.cuda.empty_cache()\n",
    "            print(f\"üîÑ New device: {device}\")\n",
    "            \n",
    "            # IMPORTANT: rerun with fresh model on CPU\n",
    "            try:\n",
    "                result = run_experiment(model_name, epochs=10)\n",
    "                results.append(result)\n",
    "            except Exception as e2:\n",
    "                print(f\"‚ùå {model_name.upper()} also failed on CPU: {e2}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Non-CUDA error, not retrying on CPU for this model.\")\n",
    "\n",
    "# Final comparison\n",
    "if results:\n",
    "    comparison_df = pd.DataFrame(results)\n",
    "    comparison_df.to_csv(r\"D:\\FoodNet\\runs\\model_comparison.csv\", index=False)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üèÅ FOODNET 10-EPOCH EXPERIMENTS COMPLETE (with GPU‚ÜíCPU fallback)!\")\n",
    "    print(comparison_df.round(2))\n",
    "    print(\"\\nüìÅ Results saved: D:\\\\FoodNet\\\\runs\\\\model_comparison.csv\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No successful runs to summarize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d116d73",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
